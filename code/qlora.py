import torch
import os
import argparse
from transformers import (
    AutoTokenizer,
    AutoModelForSeq2SeqLM,
    Seq2SeqTrainingArguments,
    Seq2SeqTrainer,
    logging,
    DataCollatorForSeq2Seq
)
from datasets import load_dataset
from typing import Dict, List, Any

# å°å…¥ PEFT ç›¸é—œå‡½å¼
from peft import LoraConfig, PeftModel, get_peft_model, TaskType, prepare_model_for_kbit_training
from accelerate import Accelerator 

logging.set_verbosity_error()

def parse_args():
    """è§£æå‘½ä»¤è¡Œåƒæ•¸ï¼Œè¨­å®šæ¨¡å‹å’Œè¨“ç·´é…ç½®ã€‚"""
    parser = argparse.ArgumentParser(description="LoRA SFT Fine-tuning script for Prompt Rewriter Model.")
    
    # --- Model and Path Arguments ---
    # å°‡é è¨­æ¨¡å‹æ›´æ”¹ç‚º Flan-T5-XL ä»¥å±•ç¤º LoRA çš„å„ªå‹¢
    parser.add_argument("--model_name", type=str, default="google/flan-t5-large", 
                        help="è¦å¾®èª¿çš„åŸºç¤æ¨¡å‹åç¨± (ä¾‹å¦‚: google/flan-t5-xl)ã€‚")
    parser.add_argument("--dataset_path", type=str, default="./data2/reward_dataset.jsonl",
                        help="åŒ…å« prompt å’Œ chosen å›æ‡‰çš„ JSON Lines æª”æ¡ˆè·¯å¾‘ã€‚")
    parser.add_argument("--output_dir", type=str, default="./models/lora_1",
                        help="LoRA æ¬Šé‡å’Œé…ç½®å„²å­˜çš„ç›®éŒ„ã€‚")
    parser.add_argument("--max_length", type=int, default=512,
                        help="åˆ†è©çš„æœ€å¤§åºåˆ—é•·åº¦ã€‚")
    parser.add_argument("--lora_path", type=str, default=None)
    # --- Training Arguments ---
    parser.add_argument("--num_epochs", type=int, default=1,
                        help="è¨“ç·´è¼ªæ•¸ (Epochs)ã€‚")
    parser.add_argument("--learning_rate", type=float, default=1e-4, # LoRA é€šå¸¸ä½¿ç”¨æ›´é«˜çš„å­¸ç¿’ç‡
                        help="å„ªåŒ–å™¨çš„å­¸ç¿’ç‡ã€‚")
    parser.add_argument("--batch_size", type=int, default=2, # LoRA å¯ä»¥ä½¿ç”¨æ›´å¤§çš„æ‰¹æ¬¡å¤§å°
                        help="æ¯å€‹è¨­å‚™çš„è¨“ç·´æ‰¹æ¬¡å¤§å° (Batch Size)ã€‚")
    
    # --- LoRA Arguments ---
    parser.add_argument("--lora_r", type=int, default=64, help="LoRA ç§© (rank)ã€‚")
    parser.add_argument("--lora_alpha", type=int, default=128, help="LoRA ç¸®æ”¾å› å­ (scaling factor)ã€‚")
    parser.add_argument("--lora_dropout", type=float, default=0.05, help="LoRA å±¤çš„ Dropout æ©Ÿç‡ã€‚")
    
    return parser.parse_args()

def load_and_tokenize_data(tokenizer: AutoTokenizer, dataset_path: str, max_length: int) -> load_dataset:
    """è¼‰å…¥è³‡æ–™é›†ï¼Œä¸¦åªä¿ç•™ 'prompt' å’Œ 'chosen' æ¬„ä½é€²è¡Œåˆ†è©ã€‚"""
    if not os.path.exists(dataset_path):
        raise FileNotFoundError(f"Dataset file not found at {dataset_path}.")
    
    print(f"Loading dataset from {dataset_path}...")
    data_files = {"train": dataset_path}
    dataset = load_dataset("json", data_files=data_files)["train"]

    if not all(col in dataset.column_names for col in ['prompt', 'chosen']):
        raise ValueError("Dataset must contain 'prompt' and 'chosen' columns.")

    def preprocess_function(examples: Dict[str, Any]) -> Dict[str, List[int]]:
        """å°‡æ–‡æœ¬è½‰æ›ç‚º tokensï¼Œä¸¦è¨­ç½®æ¨™ç±¤ (labels)ã€‚"""
        instruction_prefix = "TASK: Rewrite the unsafe INPUT prompt below. The goal is to transform the potentially harmful, malicious, or unsafe input into a less harmful and safe query. The modified query MUST strictly retain the user's original core goal and intent, changing only the elements necessary for safety. Prioritize minimizing the deviation from the original context. Do not add external context or introduce new goals. The output must be the modified prompt directly and nothing else. INPUT: "

        # 1. è¼¸å…¥ (Prompt) åˆ†è©
        inputs = [instruction_prefix + p for p in examples["prompt"]]
        model_inputs = tokenizer(inputs, max_length=max_length, truncation=True)

        # 2. æ¨™ç±¤ (Chosen Response) åˆ†è©
        # ç§»é™¤ with tokenizer.as_target_tokenizer():
        # ç”±æ–¼ T5 çš„ Encoder-Decoder çµæ§‹ï¼Œæˆ‘å€‘ç›´æ¥å°ç›®æ¨™æ–‡æœ¬é€²è¡Œåˆ†è©
        labels = tokenizer(examples["chosen"], max_length=max_length, truncation=True)

        # å°‡è§£ç¢¼å™¨è¼¸å…¥ (labels) é™„åŠ åˆ°ç·¨ç¢¼å™¨è¼¸å…¥ä¸­
        model_inputs["labels"] = labels["input_ids"]
        return model_inputs

    print("Tokenizing dataset...")
    # å¢åŠ  num_proc ä»¥åŠ å¿«åˆ†è©é€Ÿåº¦
    tokenized_datasets = dataset.map(
        preprocess_function,
        batched=True,
        remove_columns=dataset.column_names,
        num_proc=os.cpu_count(),
    )
    return tokenized_datasets

def train_sft_peft(args):
    accelerator = Accelerator()
    device = accelerator.device
    
    # --- 1. è¼‰å…¥æ¨¡å‹å’Œåˆ†è©å™¨ ---
    tokenizer = AutoTokenizer.from_pretrained(args.model_name)
    if tokenizer.pad_token is None:
        tokenizer.pad_token = tokenizer.eos_token

    print(f"Loading model {args.model_name}...")
    
    # è¨­ç½® BFLOAT16 ç²¾åº¦ä»¥ç¯€çœ VRAM
    model = AutoModelForSeq2SeqLM.from_pretrained(
        args.model_name,
        torch_dtype=torch.bfloat16,
        # åƒ…åœ¨å–®å¡è¨“ç·´æ™‚ä½¿ç”¨ device_map="auto"ï¼›ä½¿ç”¨ Accelerator/DDP æ™‚é€šå¸¸ä¸è¨­ç½®
        # device_map="auto" 
    )

    # é‡å° T5 æ¨¡å‹çš„ PEFT é…ç½®
    target_modules = ["q", "v"] # T5 æ¨¡å‹é€šå¸¸åœ¨ 'q', 'v' (Query, Value) çŸ©é™£ä¸Šæ‡‰ç”¨ LoRA
    
    # --- 2. æ‡‰ç”¨ LoRA é…ç½® ---
    peft_config = LoraConfig(
        task_type=TaskType.SEQ_2_SEQ_LM,
        inference_mode=False,
        r=args.lora_r,
        lora_alpha=args.lora_alpha,
        lora_dropout=args.lora_dropout,
        target_modules=target_modules,
        bias="none",
    )
    
    # å°‡ LoRA æ¨¡å¡Šæ·»åŠ åˆ°åŸºç¤æ¨¡å‹ä¸­
    if args.lora_path != None:
        print("Load old LoRA weight")
        model = PeftModel.from_pretrained(model, args.lora_path)

    else:
        print("Load new LoRA weight")
        model = get_peft_model(model, peft_config)
    for name, param in model.named_parameters():
        if 'lora' not in name:
            # å‡çµæ‰€æœ‰é LoRA æ¬Šé‡
            param.requires_grad = False
        else:
            # ç¢ºä¿æ‰€æœ‰ LoRA æ¬Šé‡æ˜¯å¯è¨“ç·´çš„
            param.requires_grad = True
    print("--- LoRA Model Configuration ---")
    model.print_trainable_parameters() # é¡¯ç¤ºå¯è¨“ç·´åƒæ•¸çš„æ•¸é‡
    print("--------------------------------")

    # --- 3. è¼‰å…¥ä¸¦é è™•ç†è³‡æ–™ ---
    train_dataset = load_and_tokenize_data(
        tokenizer,
        args.dataset_path,
        args.max_length
    )

    # --- 4. é…ç½® PEFT è¨“ç·´åƒæ•¸ ---
    # ç”±æ–¼ä½¿ç”¨ LoRAï¼Œæˆ‘å€‘å¯ä»¥å¢å¤§æ‰¹æ¬¡å¤§å° (Batch Size)
    optimizer_type = "adamw_torch" 

    training_args = Seq2SeqTrainingArguments(
        output_dir=args.output_dir,
        per_device_train_batch_size=args.batch_size,
        gradient_accumulation_steps=4, # ç”±æ–¼ batch_size å¢å¤§ï¼Œå¯æ¸›å°‘ç´¯ç©æ­¥é©Ÿ
        num_train_epochs=args.num_epochs,
        learning_rate=args.learning_rate,
        optim=optimizer_type,
        lr_scheduler_type="cosine",
        save_strategy="epoch",  # æ¯ epoch ä¿å­˜ä¸€æ¬¡ LoRA æ¬Šé‡
        save_total_limit=1,
        logging_strategy="steps",
        logging_steps=50,
        resume_from_checkpoint=False,
        remove_unused_columns=True,
        bf16=True, # å¿…é ˆä½¿ç”¨ BF16 ä¾†è¨“ç·´å¤§å‹æ¨¡å‹
        load_best_model_at_end=False,
        predict_with_generate=True,
    )

    data_collator = DataCollatorForSeq2Seq(
        tokenizer,
        model=model,
        padding=True
    )

    trainer = Seq2SeqTrainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        tokenizer=tokenizer,
        data_collator=data_collator,
    )

    # --- 5. å•Ÿå‹•è¨“ç·´ ---
    print("\nStarting LoRA SFT fine-tuning on Chosen responses...")
    trainer.train()

    # --- 6. å„²å­˜ LoRA æ¬Šé‡ ---
    final_lora_path = args.output_dir
    trainer.model.save_pretrained(final_lora_path)
    tokenizer.save_pretrained(final_lora_path)
    print(f"\nâœ… LoRA PEFT Fine-tuning finished. Weights saved to {final_lora_path}")

    # ğŸ’¡ è¦å°‡ LoRA æ¬Šé‡èˆ‡åŸå§‹æ¨¡å‹åˆä½µä»¥é€²è¡Œæ¨è«–ï¼Œè«‹åƒè€ƒä»¥ä¸‹ LoRA æ¬Šé‡åˆä½µæ­¥é©Ÿã€‚
    # é€™æ˜¯å¯é¸çš„ï¼Œç›´æ¥ä½¿ç”¨ peft_model.to_infer() é€²è¡Œæ¨è«–ä¹Ÿæ˜¯å¯ä»¥çš„ã€‚


if __name__ == "__main__":
    try:
        args = parse_args()
        train_sft_peft(args)
    except FileNotFoundError as e:
        print(f"Error: {e}")
        print("è«‹ç¢ºèªæ‚¨çš„æ•¸æ“šé›†æª”æ¡ˆè·¯å¾‘æ­£ç¢ºã€‚")
    except Exception as e:
        print(f"An error occurred during PEFT training: {e}")
        print("è«‹æª¢æŸ¥æ‚¨çš„ç’°å¢ƒè¨­ç½® (ä¾‹å¦‚: PyTorch, Accelerate, PEFT ç‰ˆæœ¬) å’Œ GPU é…ç½®ã€‚")
